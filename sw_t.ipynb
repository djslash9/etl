{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Table Scraper\n",
    "This notebook loads `sw_images/engagement.png`, uses EasyOCR to extract text, identifies the table starting with \"Metric\", and creates a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T02:59:47.067357Z",
     "iopub.status.busy": "2025-12-28T02:59:47.066635Z",
     "iopub.status.idle": "2025-12-28T02:59:51.030651Z",
     "shell.execute_reply": "2025-12-28T02:59:51.029878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install dependencies if not present\n",
    "# !pip install easyocr pandas opencv-python-headless\n",
    "\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T02:59:51.033727Z",
     "iopub.status.busy": "2025-12-28T02:59:51.033156Z",
     "iopub.status.idle": "2025-12-28T02:59:51.039061Z",
     "shell.execute_reply": "2025-12-28T02:59:51.038378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Image: sw_images/engagement.png\n"
     ]
    }
   ],
   "source": [
    "image_path = 'sw_images/engagement.png'\n",
    "print(f\"Target Image: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T02:59:51.066775Z",
     "iopub.status.busy": "2025-12-28T02:59:51.065861Z",
     "iopub.status.idle": "2025-12-28T03:00:00.116504Z",
     "shell.execute_reply": "2025-12-28T03:00:00.115672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 50 text elements.\n"
     ]
    }
   ],
   "source": [
    "# Initialize EasyOCR Reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Read text from image\n",
    "# output format: [[bounding_box], text, confidence]\n",
    "results = reader.readtext(image_path)\n",
    "\n",
    "# Filter for useful low-confidence text if needed, but usually default is fine\n",
    "print(f\"Extracted {len(results)} text elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T03:00:00.121089Z",
     "iopub.status.busy": "2025-12-28T03:00:00.120647Z",
     "iopub.status.idle": "2025-12-28T03:00:00.151864Z",
     "shell.execute_reply": "2025-12-28T03:00:00.150761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header Found: ['Metric', 'mobitel Ik', 'dialog Ik', 'hutch Ik', 'airtel Ik', 'slt Ik']\n"
     ]
    }
   ],
   "source": [
    "# Logic to reconstruct the table\n",
    "\n",
    "# 1. Convert results to a list of dicts for easier handling\n",
    "text_data = []\n",
    "for (bbox, text, prob) in results:\n",
    "    # bbox points: [top_left, top_right, bottom_right, bottom_left]\n",
    "    # Get center y for row grouping\n",
    "    tl, tr, br, bl = bbox\n",
    "    y_center = (tl[1] + bl[1]) / 2\n",
    "    x_center = (tl[0] + tr[0]) / 2\n",
    "    text_data.append({'text': text, 'y': y_center, 'x': x_center, 'bbox': bbox})\n",
    "\n",
    "# 2. Group by Rows (grouping text elements that are on the same line with some tolerance)\n",
    "df_text = pd.DataFrame(text_data)\n",
    "df_text = df_text.sort_values(by='y')\n",
    "\n",
    "rows = []\n",
    "current_row = []\n",
    "last_y = -1\n",
    "y_tolerance = 15  # Adjust based on image resolution\n",
    "\n",
    "for index, row in df_text.iterrows():\n",
    "    if last_y == -1 or abs(row['y'] - last_y) < y_tolerance:\n",
    "        current_row.append(row)\n",
    "        # update last_y to average or keep it? moving average might be better for slight skews\n",
    "        last_y = row['y']\n",
    "    else:\n",
    "        # Sort the completed row by X to get columns\n",
    "        current_row.sort(key=lambda x: x['x'])\n",
    "        rows.append(current_row)\n",
    "        \n",
    "        # Start new row\n",
    "        current_row = [row]\n",
    "        last_y = row['y']\n",
    "\n",
    "# Append the last row\n",
    "if current_row:\n",
    "    current_row.sort(key=lambda x: x['x'])\n",
    "    rows.append(current_row)\n",
    "\n",
    "# 3. Find the Header Row (containing \"Metric\")\n",
    "header_row_index = -1\n",
    "for i, row in enumerate(rows):\n",
    "    texts = [item['text'] for item in row]\n",
    "    if \"Metric\" in texts:\n",
    "        header_row_index = i\n",
    "        break\n",
    "\n",
    "# 4. Extract Header + 7 Data Rows\n",
    "final_rows_data = []\n",
    "\n",
    "if header_row_index != -1:\n",
    "    # Extract Header\n",
    "    # Sometimes OCR splits \"mobitel.lk\" or \"Metric\", so we take the list of text\n",
    "    header_texts = [item['text'] for item in rows[header_row_index]]\n",
    "    print(\"Header Found:\", header_texts)\n",
    "    \n",
    "    # Extract next 7 rows\n",
    "    # Note: Depending on spacing, there might be empty rows or noise.\n",
    "    # We iterate and pick the next 7 valid-looking rows (or just the next 7 in list if clean)\n",
    "    \n",
    "    data_start_idx = header_row_index + 1\n",
    "    data_rows_captured = 0\n",
    "    \n",
    "    # We want to form a table. For simplicity, we'll just grab the text lists.\n",
    "    # A more robust way aligns them to header columns by X-coordinate, \n",
    "    # but for now let's assume they are detected in order.\n",
    "    \n",
    "    extracted_table = []\n",
    "    # Header\n",
    "    extracted_table.append(header_texts)\n",
    "    \n",
    "    for i in range(data_start_idx, len(rows)):\n",
    "        if data_rows_captured >= 7:\n",
    "            break\n",
    "        \n",
    "        row_texts = [item['text'] for item in rows[i]]\n",
    "        \n",
    "        # FIX: Merge 'Visits' and 'Unique visitors' if split\n",
    "        if len(row_texts) > 1 and \"Visits\" in row_texts[0] and \"Unique\" in row_texts[1]:\n",
    "            row_texts[0] = row_texts[0] + \" / \" + row_texts[1]\n",
    "            row_texts.pop(1)\n",
    "            \n",
    "        # Simple heuristic to skip noise: row must have at least 2 items\n",
    "        if len(row_texts) >= 2:\n",
    "            extracted_table.append(row_texts)\n",
    "            data_rows_captured += 1\n",
    "    \n",
    "    # Create DataFrame\n",
    "    # Note: Row lengths might mismatch if OCR missed some values (e.g. \"-\" or small text)\n",
    "    # We'll normalize length to the header length\n",
    "    header = extracted_table[0]\n",
    "    data = extracted_table[1:]\n",
    "    \n",
    "    # Ensure all data rows match header length by padding or trimming\n",
    "    # (In a real scenario, we'd map by X-coordinate to handle missing cells)\n",
    "    normalized_data = []\n",
    "    for r in data:\n",
    "        if len(r) < len(header):\n",
    "            r = r + [None] * (len(header) - len(r))\n",
    "        elif len(r) > len(header):\n",
    "             # This is tricky; maybe OCR merged header columns or split data columns.\n",
    "             # For now, slice it.\n",
    "            r = r[:len(header)]\n",
    "        normalized_data.append(r)\n",
    "        \n",
    "    df = pd.DataFrame(normalized_data, columns=header)\n",
    "\n",
    "    # Transpose DataFrame as requested\n",
    "    if 'Metric' in df.columns:\n",
    "        df_engagement = df.set_index('Metric').T\n",
    "    else:\n",
    "        # Fallback if OCR messed up the column name 'Metric'\n",
    "        # Assume first column is metric\n",
    "        df_engagement = df.set_index(df.columns[0]).T\n",
    "        \n",
    "    # Data Cleaning Logic\n",
    "    def clean_value(x):\n",
    "        if not isinstance(x, str):\n",
    "            return x\n",
    "        x = x.strip()\n",
    "        \n",
    "        # Handle explicitly known non-numeric placeholders\n",
    "        if x.upper() in ['N/A', 'NIA', 'NAN', 'NONE', '', '-']:\n",
    "            return 0\n",
    "        \n",
    "        # Handle M (Millions)\n",
    "        if 'M' in x:\n",
    "            try:\n",
    "                return float(x.replace('M', '').replace(',', '')) * 1_000_000\n",
    "            except:\n",
    "                return 0\n",
    "        # Handle % (Percentage)\n",
    "        if '%' in x:\n",
    "            try:\n",
    "                return float(x.replace('%', '').replace(',', '')) * 0.01\n",
    "            except:\n",
    "                return 0\n",
    "        # Try to convert string numbers to float/int if possible (handle commas)\n",
    "        try:\n",
    "            val_cleaned = x.replace(',', '')\n",
    "            if '.' in val_cleaned:\n",
    "                return float(val_cleaned)\n",
    "            else:\n",
    "                return int(val_cleaned)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    df_engagement = df_engagement.applymap(clean_value)\n",
    "        \n",
    "else:\n",
    "    print(\"Could not find a row containing 'Metric'.\")\n",
    "    df_engagement = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T03:00:00.155135Z",
     "iopub.status.busy": "2025-12-28T03:00:00.154782Z",
     "iopub.status.idle": "2025-12-28T03:00:00.178765Z",
     "shell.execute_reply": "2025-12-28T03:00:00.177450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference File: sw_images/engagement.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metric</th>\n",
       "      <th>Monthly visits</th>\n",
       "      <th>Monthly unique visitors</th>\n",
       "      <th>Visits / Unique visitors</th>\n",
       "      <th>Visit duration</th>\n",
       "      <th>Pages per visit</th>\n",
       "      <th>Bounce rate</th>\n",
       "      <th>Page Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mobitel Ik</th>\n",
       "      <td>1281000.0</td>\n",
       "      <td>399619</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.3797</td>\n",
       "      <td>4628000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dialog Ik</th>\n",
       "      <td>2689000.0</td>\n",
       "      <td>971059</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>7332000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hutch Ik</th>\n",
       "      <td>506387.0</td>\n",
       "      <td>168630</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>1314000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airtel Ik</th>\n",
       "      <td>623606.0</td>\n",
       "      <td>144970</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>1652000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slt Ik</th>\n",
       "      <td>1354000.0</td>\n",
       "      <td>282834</td>\n",
       "      <td>4.79</td>\n",
       "      <td>0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>5990000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric      Monthly visits  Monthly unique visitors  Visits / Unique visitors  \\\n",
       "mobitel Ik       1281000.0                   399619                      3.21   \n",
       "dialog Ik        2689000.0                   971059                      2.77   \n",
       "hutch Ik          506387.0                   168630                      3.00   \n",
       "airtel Ik         623606.0                   144970                      4.30   \n",
       "slt Ik           1354000.0                   282834                      4.79   \n",
       "\n",
       "Metric      Visit duration  Pages per visit  Bounce rate  Page Views  \n",
       "mobitel Ik               0             3.61       0.3797   4628000.0  \n",
       "dialog Ik                0             2.73       0.5290   7332000.0  \n",
       "hutch Ik                 0             2.60       0.5574   1314000.0  \n",
       "airtel Ik                0             2.65       0.5020   1652000.0  \n",
       "slt Ik                   0             4.42       0.3097   5990000.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Transposed DataFrame\n",
    "print(\"Reference File:\", image_path)\n",
    "df_engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Network Data Extraction\n",
    "Processing `sw_images/social_network.png` to extract the defined table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T03:00:00.183172Z",
     "iopub.status.busy": "2025-12-28T03:00:00.182465Z",
     "iopub.status.idle": "2025-12-28T03:00:09.613443Z",
     "shell.execute_reply": "2025-12-28T03:00:09.612459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Image: sw_images/social_network.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Headers: ['Networks', 'mobitel Ik', 'dialog Ik', 'hutchIk', 'airtel Ik', 'slt Ik']\n",
      "Raw Social DataFrame (Corrected Alignment):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Networks</th>\n",
       "      <th>mobitel Ik</th>\n",
       "      <th>dialog Ik</th>\n",
       "      <th>hutchIk</th>\n",
       "      <th>airtel Ik</th>\n",
       "      <th>slt Ik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>13.08%</td>\n",
       "      <td>18.79%</td>\n",
       "      <td>20.10%</td>\n",
       "      <td>0%</td>\n",
       "      <td>67.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>0%</td>\n",
       "      <td>17.15%</td>\n",
       "      <td>61.78%</td>\n",
       "      <td>35.76%</td>\n",
       "      <td>22.14%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linkedin</td>\n",
       "      <td>14.25%</td>\n",
       "      <td>40.64%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WhatsApp Webapp</td>\n",
       "      <td>14.67%</td>\n",
       "      <td>20.79%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>6.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Social</td>\n",
       "      <td>26.00%</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>18.12%</td>\n",
       "      <td>64.24%</td>\n",
       "      <td>0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Academia</td>\n",
       "      <td>31.99%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Others</td>\n",
       "      <td>0%</td>\n",
       "      <td>2.63%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3.82%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Networks mobitel Ik dialog Ik hutchIk airtel Ik  slt Ik\n",
       "0          Youtube     13.08%    18.79%  20.10%        0%  67.25%\n",
       "1         Facebook         0%    17.15%  61.78%    35.76%  22.14%\n",
       "2         Linkedin     14.25%    40.64%      0%        0%      0%\n",
       "3  WhatsApp Webapp     14.67%    20.79%      0%        0%   6.79%\n",
       "4           Social     26.00%     0.01%  18.12%    64.24%   0.01%\n",
       "5         Academia     31.99%        0%      0%        0%      0%\n",
       "6           Others         0%     2.63%      0%        0%   3.82%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Social DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Networks</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Linkedin</th>\n",
       "      <th>WhatsApp Webapp</th>\n",
       "      <th>Social</th>\n",
       "      <th>Academia</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mobitel Ik</th>\n",
       "      <td>13.08%</td>\n",
       "      <td>0%</td>\n",
       "      <td>14.25%</td>\n",
       "      <td>14.67%</td>\n",
       "      <td>26.00%</td>\n",
       "      <td>31.99%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dialog Ik</th>\n",
       "      <td>18.79%</td>\n",
       "      <td>17.15%</td>\n",
       "      <td>40.64%</td>\n",
       "      <td>20.79%</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0%</td>\n",
       "      <td>2.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hutchIk</th>\n",
       "      <td>20.10%</td>\n",
       "      <td>61.78%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>18.12%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airtel Ik</th>\n",
       "      <td>0%</td>\n",
       "      <td>35.76%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>64.24%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slt Ik</th>\n",
       "      <td>67.25%</td>\n",
       "      <td>22.14%</td>\n",
       "      <td>0%</td>\n",
       "      <td>6.79%</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>0%</td>\n",
       "      <td>3.82%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Networks   Youtube Facebook Linkedin WhatsApp Webapp  Social Academia Others\n",
       "mobitel Ik  13.08%       0%   14.25%          14.67%  26.00%   31.99%     0%\n",
       "dialog Ik   18.79%   17.15%   40.64%          20.79%   0.01%       0%  2.63%\n",
       "hutchIk     20.10%   61.78%       0%              0%  18.12%       0%     0%\n",
       "airtel Ik       0%   35.76%       0%              0%  64.24%       0%     0%\n",
       "slt Ik      67.25%   22.14%       0%           6.79%   0.01%       0%  3.82%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Social Network Extraction\n",
    "sn_image_path = 'sw_images/social_network.png'\n",
    "print(f\"Target Image: {sn_image_path}\")\n",
    "\n",
    "# Read text from image\n",
    "# Using regex to fix common issues in post-processing\n",
    "# Adjusting mag_ratio to catch small text\n",
    "sn_results = reader.readtext(sn_image_path, mag_ratio=1.5)\n",
    "\n",
    "# 1. Convert to list of dicts\n",
    "sn_text_data = []\n",
    "for (bbox, text, prob) in sn_results:\n",
    "    tl, tr, br, bl = bbox\n",
    "    y_center = (tl[1] + bl[1]) / 2\n",
    "    x_center = (tl[0] + tr[0]) / 2\n",
    "    \n",
    "    # CLEANUP: \n",
    "    # 1. Remove '<' (e.g. '< 0.01%')\n",
    "    text = text.replace('<', '').strip()\n",
    "    \n",
    "    # 2. Fix '9' at end instead of '%'\n",
    "    # Pattern: Digit(s) + '9' -> Digit(s) + '%'\n",
    "    if re.match(r'^[\\d\\.]*9$', text) and len(text) > 1:\n",
    "        text = text[:-1] + '%'\n",
    "    \n",
    "    sn_text_data.append({'text': text, 'y': y_center, 'x': x_center})\n",
    "\n",
    "# 2. Group by Rows\n",
    "df_sn_text = pd.DataFrame(sn_text_data)\n",
    "df_sn_text = df_sn_text.sort_values(by='y')\n",
    "\n",
    "sn_rows = []\n",
    "sn_current_row = []\n",
    "sn_last_y = -1\n",
    "\n",
    "for index, row in df_sn_text.iterrows():\n",
    "    if sn_last_y == -1 or abs(row['y'] - sn_last_y) < y_tolerance:\n",
    "        sn_current_row.append(row)\n",
    "        sn_last_y = row['y']\n",
    "    else:\n",
    "        sn_current_row.sort(key=lambda x: x['x'])\n",
    "        sn_rows.append(sn_current_row)\n",
    "        sn_current_row = [row]\n",
    "        sn_last_y = row['y']\n",
    "\n",
    "if sn_current_row:\n",
    "    sn_current_row.sort(key=lambda x: x['x'])\n",
    "    sn_rows.append(sn_current_row)\n",
    "\n",
    "# 3. Find Header (Looking for \"Network\")\n",
    "sn_header_row_index = -1\n",
    "for i, row in enumerate(sn_rows):\n",
    "    texts = [item['text'] for item in row]\n",
    "    if any(\"Network\" in t for t in texts):\n",
    "        sn_header_row_index = i\n",
    "        break\n",
    "\n",
    "# 4. Extract Data with X-Coordinate Alignment\n",
    "if sn_header_row_index != -1:\n",
    "    # Get Headers with their X Coordinates\n",
    "    header_items = sn_rows[sn_header_row_index]\n",
    "    sn_headers = [{'text': item['text'], 'x': item['x']} for item in header_items]\n",
    "    print(\"Social Headers:\", [h['text'] for h in sn_headers])\n",
    "    \n",
    "    sn_extracted_data = []\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(sn_header_row_index + 1, len(sn_rows)):\n",
    "        if count >= 7: break\n",
    "        \n",
    "        row_items = sn_rows[i]\n",
    "        if len(row_items) < 1: continue\n",
    "        \n",
    "        # Initialize row with Nones\n",
    "        mapped_row = {h['text']: None for h in sn_headers}\n",
    "        \n",
    "        # Map each item to the nearest header\n",
    "        for item in row_items:\n",
    "            closest_header = min(sn_headers, key=lambda h: abs(h['x'] - item['x']))\n",
    "            \n",
    "            # Check if existing value is there (collision)\n",
    "            # If so, maybe concatenate or choose better?\n",
    "            if mapped_row[closest_header['text']] is not None:\n",
    "                 # Append or overwrite? For now append to debug\n",
    "                 mapped_row[closest_header['text']] += \" \" + item['text']\n",
    "            else:\n",
    "                mapped_row[closest_header['text']] = item['text']\n",
    "        \n",
    "        sn_extracted_data.append(mapped_row)\n",
    "        count += 1\n",
    "            \n",
    "    df_sn = pd.DataFrame(sn_extracted_data)\n",
    "    \n",
    "    # Replace None with \"0%\"\n",
    "    df_sn = df_sn.fillna(\"0%\")\n",
    "    \n",
    "    print(\"Raw Social DataFrame (Corrected Alignment):\")\n",
    "    display(df_sn)\n",
    "    \n",
    "    # Transpose\n",
    "    network_col = next((c for c in df_sn.columns if \"Network\" in c), None)\n",
    "    if network_col:\n",
    "        df_social = df_sn.set_index(network_col).T\n",
    "    else:\n",
    "        df_social = df_sn.set_index(df_sn.columns[0]).T\n",
    "        \n",
    "    print(\"Transformed Social DataFrame:\")\n",
    "    display(df_social)\n",
    "else:\n",
    "    print(\"Could not find 'Network' header row.\")\n",
    "    df_social = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Traffic Extraction\n",
    "Looping through `channel_traffic-*.png` to extract channel-specific data and merge into a single summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T03:00:09.617999Z",
     "iopub.status.busy": "2025-12-28T03:00:09.617319Z",
     "iopub.status.idle": "2025-12-28T03:00:22.698775Z",
     "shell.execute_reply": "2025-12-28T03:00:22.697735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 channel files.\n",
      "Processing: channel_traffic-direct.png -> Column: direct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-display.png -> Column: display\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-email.png -> Column: email\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-gen_ai.png -> Column: gen_ai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-referrals.png -> Column: referrals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-search_organic.png -> Column: search_organic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-search_paid.png -> Column: search_paid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-social_organic.png -> Column: social_organic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: channel_traffic-social_paid.png -> Column: social_paid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Channel Traffic DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "      <th>direct</th>\n",
       "      <th>display</th>\n",
       "      <th>email</th>\n",
       "      <th>gen_ai</th>\n",
       "      <th>referrals</th>\n",
       "      <th>search_organic</th>\n",
       "      <th>search_paid</th>\n",
       "      <th>social_organic</th>\n",
       "      <th>social_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airtel Ik</td>\n",
       "      <td>319637.0</td>\n",
       "      <td>81561</td>\n",
       "      <td>1467</td>\n",
       "      <td>0</td>\n",
       "      <td>100556</td>\n",
       "      <td>1315000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10127</td>\n",
       "      <td>42328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dialog Ik</td>\n",
       "      <td>3653000.0</td>\n",
       "      <td>177850</td>\n",
       "      <td>38060</td>\n",
       "      <td>35330</td>\n",
       "      <td>288045</td>\n",
       "      <td>3487000.0</td>\n",
       "      <td>173130</td>\n",
       "      <td>164103</td>\n",
       "      <td>49952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hutch Ik</td>\n",
       "      <td>696452.0</td>\n",
       "      <td>10020</td>\n",
       "      <td>6055</td>\n",
       "      <td>2045</td>\n",
       "      <td>55028</td>\n",
       "      <td>707877.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15504</td>\n",
       "      <td>26181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobitel Ik</td>\n",
       "      <td>1659000.0</td>\n",
       "      <td>28404</td>\n",
       "      <td>1538</td>\n",
       "      <td>13981</td>\n",
       "      <td>263114</td>\n",
       "      <td>1766000.0</td>\n",
       "      <td>84979</td>\n",
       "      <td>22774</td>\n",
       "      <td>4601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slt Ik</td>\n",
       "      <td>3180000.0</td>\n",
       "      <td>8196</td>\n",
       "      <td>7512</td>\n",
       "      <td>1908</td>\n",
       "      <td>138158</td>\n",
       "      <td>686412.0</td>\n",
       "      <td>8890</td>\n",
       "      <td>24524</td>\n",
       "      <td>7394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Website     direct  display  email  gen_ai  referrals  search_organic  \\\n",
       "0   airtel Ik   319637.0    81561   1467       0     100556       1315000.0   \n",
       "1   dialog Ik  3653000.0   177850  38060   35330     288045       3487000.0   \n",
       "2    hutch Ik   696452.0    10020   6055    2045      55028        707877.0   \n",
       "3  mobitel Ik  1659000.0    28404   1538   13981     263114       1766000.0   \n",
       "4      slt Ik  3180000.0     8196   7512    1908     138158        686412.0   \n",
       "\n",
       "   search_paid  social_organic  social_paid  \n",
       "0            0           10127        42328  \n",
       "1       173130          164103        49952  \n",
       "2            0           15504        26181  \n",
       "3        84979           22774         4601  \n",
       "4         8890           24524         7394  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Channel Traffic Extraction Logic\n",
    "\n",
    "channel_files = glob.glob('sw_images/channel_traffic-*.png')\n",
    "print(f\"Found {len(channel_files)} channel files.\")\n",
    "\n",
    "# Placeholder for the merged DataFrame\n",
    "df_channels = pd.DataFrame()\n",
    "\n",
    "for fpath in channel_files:\n",
    "    # Extract suffix from filename (e.g. 'direct' from 'channel_traffic-direct.png')\n",
    "    base_name = os.path.basename(fpath)\n",
    "    # format is 'channel_traffic-<suffix>.png'\n",
    "    # split by '-' then remove extension\n",
    "    # assumption: filename format is strict\n",
    "    try:\n",
    "        suffix = base_name.split('channel_traffic-')[1].replace('.png', '')\n",
    "    except IndexError:\n",
    "        print(f\"Skipping file with unexpected format: {base_name}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {base_name} -> Column: {suffix}\")\n",
    "    \n",
    "    # OCR\n",
    "    # Using mag_ratio=1.5 for consistency, though default might suffice for larger text\n",
    "    results = reader.readtext(fpath, mag_ratio=1.5)\n",
    "    \n",
    "    # Standard Row Grouping Logic (reused)\n",
    "    c_text_data = []\n",
    "    for (bbox, text, prob) in results:\n",
    "        tl, tr, br, bl = bbox\n",
    "        y_center = (tl[1] + bl[1]) / 2\n",
    "        x_center = (tl[0] + tr[0]) / 2\n",
    "        \n",
    "        # Clean values immediately if simple\n",
    "        text = text.replace('<', '').strip()\n",
    "        # Fix common digit-percent error\n",
    "        if re.match(r'^[\\d\\.]*9$', text) and len(text) > 1:\n",
    "            text = text[:-1] + '%'\n",
    "            \n",
    "        c_text_data.append({'text': text, 'y': y_center, 'x': x_center})\n",
    "        \n",
    "    df_c = pd.DataFrame(c_text_data)\n",
    "    if df_c.empty:\n",
    "        print(f\"No text found in {base_name}\")\n",
    "        continue\n",
    "        \n",
    "    df_c = df_c.sort_values(by='y')\n",
    "    \n",
    "    c_rows = []\n",
    "    c_current = []\n",
    "    last_y = -1\n",
    "    # Use same tolerance\n",
    "    y_tolerance = 15\n",
    "    \n",
    "    for index, row in df_c.iterrows():\n",
    "        if last_y == -1 or abs(row['y'] - last_y) < y_tolerance:\n",
    "            c_current.append(row)\n",
    "            last_y = row['y']\n",
    "        else:\n",
    "            c_current.sort(key=lambda x: x['x'])\n",
    "            c_rows.append(c_current)\n",
    "            c_current = [row]\n",
    "            last_y = row['y']\n",
    "    if c_current:\n",
    "         c_current.sort(key=lambda x: x['x'])\n",
    "         c_rows.append(c_current)\n",
    "\n",
    "    # Construct DataFrame for this file\n",
    "    # Expectation: Each row has 2 items: [Website Name, Value]\n",
    "    # or loop until we find rows with >= 2 items or looks like a table\n",
    "    extracted_data = []\n",
    "    \n",
    "    for row in c_rows:\n",
    "        texts = [item['text'] for item in row]\n",
    "        # Heuristic: skip headers like 'Website', 'Direct', etc. if they appear\n",
    "        # We assume the actual data rows contain the website names we know (mobitel, dialog etc) \n",
    "        # OR we just grab everything with 2 columns and filter later.\n",
    "        \n",
    "        # Let's filter for rows with exactly 2 items, as presumably these are [site, value]\n",
    "        # If there are more, OCR might have split a name.\n",
    "        if len(texts) >= 2:\n",
    "            # Assuming First is Website, Last is Value (middle might be noise or split name)\n",
    "            # If split name: \"mobitel\", \"Ik\" -> join them?\n",
    "            # Simple join of all except last is safer for name\n",
    "            website = \" \".join(texts[:-1])\n",
    "            value = texts[-1]\n",
    "            \n",
    "            # NORMALIZATION START\n",
    "            # 1. Replace '.' with ' ' (e.g. 'airtel.Ik' -> 'airtel Ik')\n",
    "            website = website.replace('.', ' ')\n",
    "            # 2. Fix missing space before 'Ik' (e.g. 'hutchIk' -> 'hutch Ik')\n",
    "            if 'Ik' in website and ' Ik' not in website:\n",
    "                website = website.replace('Ik', ' Ik')\n",
    "            # 3. Strip extra whitespace\n",
    "            website = website.strip()\n",
    "            # NORMALIZATION END\n",
    "            \n",
    "            extracted_data.append({'Website': website, suffix: value})\n",
    "            \n",
    "    # Create temp DF\n",
    "    df_temp = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    # Clean Value Column immediately\n",
    "    if not df_temp.empty:\n",
    "        df_temp[suffix] = df_temp[suffix].apply(clean_value)\n",
    "    \n",
    "    # Merge\n",
    "    if df_channels.empty:\n",
    "        df_channels = df_temp\n",
    "    else:\n",
    "        # Merge on Website\n",
    "        # Note: Website names must match EXACTLY relative to previous files for this to work perfectly.\n",
    "        # If OCR varies ('mobitel Ik' vs 'mobitel lk'), we get dupes / NaNs.\n",
    "        # For this exercise, we assume consistent OCR or accept slight fragmentation.\n",
    "        df_channels = pd.merge(df_channels, df_temp, on='Website', how='outer')\n",
    "\n",
    "print(\"Merged Channel Traffic DataFrame:\")\n",
    "display(df_channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
